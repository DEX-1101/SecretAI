{"cells":[{"cell_type":"markdown","metadata":{"id":"KZ88G-iWCTs7"},"source":["Based on 4chan NovelAILeaks (naifu)[src](https://boards.4channel.org/g/thread/89095460#p89097704)\n","\n","maintained by : [x1101](https://github.com/DEX-1101)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1667899971545,"user":{"displayName":"x1101 (FX_)","userId":"11994423749225622058"},"user_tz":-420},"id":"X5yF8TS1CR3L","outputId":"48e46b4c-5cff-40ba-e31b-7113c042625c"},"outputs":[],"source":["#@title ### 0. Check GPU working status\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136868,"status":"ok","timestamp":1667900124591,"user":{"displayName":"x1101 (FX_)","userId":"11994423749225622058"},"user_tz":-420},"id":"iqTO_Uf3F6VW","outputId":"9988a2d5-d3f5-4f38-e616-7cdaad4be939"},"outputs":[],"source":["#@title ### 1. Download Novel AI API backend, model\n","#@markdown If the download speed is too slow try restart\n","\n","%cd /content/\n","!apt install -y -qq aria2\n","!aria2c --summary-interval=5 -x 3 --allow-overwrite=true -Z \\\n","   https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/naifu.tar \\\n","   https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animefull-latest.tar\n","  \n","!echo \"Decompressing API Backend...\"\n","!tar xf naifu.tar && rm naifu.tar\n","!mkdir -p /content/naifu/models/animefull-latest\n","!echo \"Decompressing 7 GB Model...\"\n","!tar xf animefull-latest.tar -C /content/naifu/models/animefull-latest && rm animefull-latest.tar\n","\n","!echo \"Applying fixes...\"\n","# fix cant import 'rank_zero_only')\n","%cd /content/naifu\n","!curl -Lo requirements.txt https://raw.githubusercontent.com/DEX-1101/SecretAI/main/fix/requirements.txt\n","!echo \"Done.\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ### 1. (backup) Download Model / Api Backend via Google Drive\n","#@markdown Might not work cause download limit by Google Drive \n","\n","%cd /content/\n","!gdown 1-6EuAEIZVi_fOp3_ArHeP8XjPNmQb2sa -O /content/naifu.tar\n","!gdown 1-8to6FC_U55GNJwIbWqwzHefFuspF_RA -O /content/animefull-latest.tar\n","\n","!echo \"Decompressing...\"\n","!tar xf naifu.tar && rm naifu.tar\n","\n","!mkdir -p /content/naifu/models/animefull-latest\n","!echo \"Decompressing 7 GB Model...\"\n","!tar xf animefull-latest.tar -C /content/naifu/models/animefull-latest\n","\n","!echo \"Applying fix...\"\n","# fix cant import 'rank_zero_only')\n","%cd /content/naifu\n","!curl -Lo requirements.txt https://raw.githubusercontent.com/DEX-1101/SecretAI/main/fix/requirements.txt\n","!echo \"Done.\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ### 1. (backup) Run Directly via Google Drive\n","#@markdown You need the file `naifu.tar`` and `animefull-latest.tar` in your Goodle Drive Storage first, then the code will unpacking the file directly\n","\n","# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/NAI Model/ # Path of source files, CHANGE THIS !!!\n","!echo \"Decompressing API Backend...\"\n","!tar xf naifu.tar -C /content\n","\n","!mkdir -p /content/naifu/models/animefull-latest\n","!echo \"Decompressing 7 GB Model...\"\n","!tar xf animefull-latest.tar -C /content/naifu/models/animefull-latest\n","\n","!echo \"Applying fix...\"\n","# fix cant import 'rank_zero_only')\n","%cd /content/naifu\n","!curl -Lo requirements.txt https://raw.githubusercontent.com/DEX-1101/SecretAI/main/fix/requirements.txt\n","!echo \"Done.\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":220424,"status":"ok","timestamp":1667900351588,"user":{"displayName":"x1101 (FX_)","userId":"11994423749225622058"},"user_tz":-420},"id":"BysBfYRmGSo1","outputId":"4a3af7e2-1b85-43cc-99ef-73da63517737"},"outputs":[],"source":["#@title ### 2. Install dependencies\n","#@markdown Wait patiently for the installation to complete\n","\n","%cd /content/naifu\n","!pip install virtualenv && bash ./setup.sh\n","!curl -Ls https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz | tar zx -C /usr/bin\n","!curl -Lo /usr/bin/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 && chmod +x /usr/bin/cloudflared\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"uQBR9zXQGJrn"},"outputs":[],"source":["#@title ### 3. Start the model\n","#@markdown Just visit the output mapping address (end with `trycloudflare.com` / `bore.pub`).\n","#@markdown - Please wait until the model is loaded (`Application startup complete` appears) before accessing\n","#@markdown - The service provided by cloudflare occasionally has a request timeout, which can be replaced by bore tunnel\n","\n","%cd /content/naifu\n","!sed -i 's/# export SAVE_FILES=\"1\"/export SAVE_FILES=\"1\"/g' run.sh\n","!bash run.sh & cloudflared tunnel --url localhost:6969"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9j9thAby5_2","outputId":"b208f6a4-0c7a-43fa-f2d0-9bd05d2aa672"},"outputs":[],"source":["#@title ### 4. (Optional) Run with `animefull-latest` model of 7G\n","#@markdown uses the 4G size animefull-final-pruned model by default. If you want to use the 7G animefull-latest model, run this\n","\n","%cd /content/\n","!tar xf animefull-latest.tar -C /content/naifu/models && rm animefull-latest.tar\n","!sed -i 's/map_location=\"cpu\"/map_location=\"cuda\"/g' /content/naifu/hydra_node/models.py\n","\n","%cd /content/naifu\n","%env DTYPE=float16\n","%env CLIP_CONTEXTS=3\n","%env AMP=1\n","%env MODEL=stable-diffusion\n","%env DEV=True\n","# %env MODEL_PATH=models/animefull-latest\n","%env MODEL_PATH=models\n","%env ENABLE_EMA=1\n","%env VAE_PATH=models/animevae.pt\n","%env PENULTIMATE=1\n","%env PYTHONDONTWRITEBYTECODE=1`\n","%env SAVE_FILES=1\n","\n","!./venv/bin/python -m uvicorn --host 0.0.0.0 --port=6969 main:app & bore local 6969 --to bore.pub & cloudflared tunnel --url localhost:6969\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
